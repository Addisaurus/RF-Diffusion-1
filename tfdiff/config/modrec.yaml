task_id: 4
log_dir: ./log/modrec
model_dir: ./model #/modrec/debug-batch4-blocks4-tsl128
data_dir:
  - C:\Users\acnut\Coding\csp_dataset
  - C:\Users\acnut\Coding\csp_dataset\signal_record_C_2023.txt
  # - C:\Users\acnut\Coding\csp_dataset_tiny
  # - C:\Users\acnut\Coding\csp_dataset_tiny\signal_record_C_2023.txt
out_dir: ./dataset/modrec/output

# Training params
max_iter: null
batch_size: 64
learning_rate: 1.0e-3 #1.0e-4  # Reduced from 1.0e-3
max_grad_norm: 1.0  # Add explicit gradient clipping #null

# Inference params
inference_batch_size: 1
robust_sampling: true

# Data params
sample_rate: 32768          # Original signal sampling rate
target_sequence_length: 128 #128 #512 #2048 # Length we'll downsample to for the model
# Parameter for attention chunking
chunk_size: 32 #32 #128  # Process sequences in chunks of 128
input_dim: 1
extra_dim: [1]

# Model params
embed_dim: 256
hidden_dim: 256
num_heads: 8
num_block: 8 #4  #32 # Fewer transformer blocks for quick debug
dropout: 0.1    # Add some dropout for regularization
mlp_ratio: 4
learn_tfdiff: False # WHAT HAPPENS IF TF DIFF IS FALSE???

# Conditioning configuration
conditioning:
  enabled_fields:
    - mod_type  # Required field
    # Comment out fields to disable them:
    #- symbol_period
    #- carrier_offset
    #- excess_bw
    #- snr
  field_configs:
    mod_type:
      type: "categorical"
      values: ["bpsk", "qpsk", "8psk", "dqpsk", "16qam", "64qam", "256qam", "msk"]
      required: true
    symbol_period:
      type: "continuous"
      normalize: true
      required: false
      min_value: 1.0
      max_value: 10.0
    carrier_offset:
      type: "continuous"
      normalize: true
      required: false
      min_value: -500
      max_value: 500
    excess_bw:
      type: "continuous"
      normalize: true
      required: false
      min_value: 0.0
      max_value: 1.0
    snr:
      type: "continuous"
      normalize: true
      required: false
      min_value: -10
      max_value: 30

# Diffusion params
signal_diffusion: true
max_step: 100 #300

# Schedule configuration with independent types
schedule_config:
  blur_schedule:
    type: "exponential" #"cosine"  # Can be: "linear", "cosine", "exponential", "paper"
    start: 0.001
    end: 0.3 #.2
    paper_values: [0.001, 0.001, 0.002, 0.002, 0.005, 0.007, 0.01, 0.02,
                  0.03, 0.04, 0.05, 0.07, 0.1, 0.15, 0.2, 0.3]
    
  noise_schedule:
    type: "exponential" #"exponential"  # Can be different from blur schedule
    start: 0.0001
    end: 0.03 #.02
    paper_values: [0.0001, 0.0001, 0.0002, 0.0002, 0.0005, 0.0007, 0.001, 0.002, 
                  0.003, 0.004, 0.005, 0.007, 0.01, 0.015, 0.02, 0.03]

# These will be computed by the schedule generator
# blur_schedule: null
# noise_schedule: null


# Add these lines to modrec.yaml (keep all your existing config)
debug_config:
  # Control debug output for tensor shapes, dimensions, and structural info
  shape_debug: false
  # Control debug output for numerical values, statistics, gradients etc
  value_debug: false
  # Log level for non-debug messages
  log_level: "INFO"
  # Enable debugging for specific modules
  debug_modules:
    model: false
    metrics: false
    complex: false
    memory: false